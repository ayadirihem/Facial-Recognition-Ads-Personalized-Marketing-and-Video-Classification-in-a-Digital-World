{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plot\nimport cv2 as cv\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport os\nimport time\nimport pickle\n\nimport tensorflow as tf\nfrom tensorflow.python.keras.utils.data_utils import get_file\n\n\n\nclassesFilePath = '/kaggle/input/datasetobjct/coco.names'\ncacheDir = \"/kaggle/working/pretrained_models\"\nmodelMobilnet = \"http://download.tensorflow.org/models/object_detection/tf2/20200711/faster_rcnn_resnet50_v1_640x640_coco17_tpu-8.tar.gz\"\n\n\n\ndef readClasses(classesFilePath):\n    with open(classesFilePath, 'r') as f:\n        classesList = f.read().splitlines()\n        \n        # Colors list\n        colorList = np.random.uniform(low=0, high=255, size=(len(classesList),3))\n    return classesList, colorList\n\ndef downloadModel(modelURL):\n    fileName = os.path.basename(modelURL)\n    modelName = fileName[:fileName.index('.')]\n    cacheDir = \"./pretrained_models\"\n    os.makedirs(cacheDir, exist_ok=True)\n    get_file(fname=fileName, origin=modelURL, \n              cache_dir=cacheDir,\n              cache_subdir= \"checkpoints\", \n              extract=True)\n    return modelName\n\n\n\n\ndef loadModel(modelName, cacheDir):\n    print(\"Loading Model \"+modelName)\n    tf.keras.backend.clear_session()\n    model = tf.saved_model.load(\n        os.path.join(cacheDir, \"checkpoints\", modelName, \"saved_model\"))\n    print(\"\\n Model \"+ modelName+ \" Loaded successfully...\\n\")\n    return model\n\ndef createBoundingBox(image, model,classesList,colorList, threshold=0.5, objectList=[]):\n    inputTensor = cv.cvtColor(image.copy(), cv.COLOR_BGR2RGB)\n    \n    inputTensor = tf.convert_to_tensor(inputTensor, dtype=tf.uint8)\n    inputTensor = inputTensor[tf.newaxis, ...]\n    \n    detections = model(inputTensor)\n    \n    bboxs = detections['detection_boxes'][0].numpy()\n    classIndexes = detections['detection_classes'][0].numpy().astype(np.int32)\n    classScores = detections['detection_scores'][0].numpy()\n    \n    imH, imW, imC = image.shape\n    \n    bboxIdx = tf.image.non_max_suppression(bboxs, classScores, max_output_size=50,\n                                          iou_threshold=threshold, score_threshold=threshold)\n    \n    if len(bboxIdx) != 0:\n        for i in bboxIdx:\n            bbox = tuple(bboxs[i].tolist())\n            classConfidence = round((100*classScores[i]))\n        \n            classIndex = classIndexes[i]\n            classLabelText = classesList[classIndex]\n            classColor = colorList[classIndex]\n            objectList.append(classLabelText)\n\n\ndef predictImage(imagePath, model, classesList, colorList, threshold):\n    image = cv.imread(imagePath)\n    bboxImage = createBoundingBox(image, model, classesList, colorList, threshold)\n    \n    plot.imshow(bboxImage)\n\n\n\ndef predictVideo(videoPath, model, classesList, colorList, threshold= 0.5, ObjectList=[]):\n    cap = cv.VideoCapture(videoPath)\n    \n    if(cap.isOpened() == False):\n        print(\"Error opening file ...\")\n        return\n    (success, image) = cap.read()\n    \n    startTime = 0\n    \n    while success:\n        print('Video processing ..')\n        currentTime = time.time()\n        \n        fps = 1/(currentTime - startTime)\n        startTime = currentTime\n        \n        createBoundingBox(image,model, classesList, colorList,threshold,ObjectList)\n        \n        (success, image) = cap.read()\n\n\n\n\ndef get_Objects(videoPath):\n    classesList, colorList= readClasses(classesFilePath)\n    ModelName = downloadModel(modelMobilnet)\n    model = loadModel(ModelName, cacheDir)\n    print('starting Object Detection ..')\n    ObjectList = list()\n    predictVideo(videoPath,model, classesList, colorList, 0.5, ObjectList)\n    ObjectList = set(ObjectList)\n    print('Ending Object Detection ..')\n    return ObjectList\n","metadata":{"_uuid":"62fca5c9-8fb4-4553-847e-e2fa5a6f3d0e","_cell_guid":"7c30f7f6-90c0-4e49-b763-212108af93c0","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]}]}